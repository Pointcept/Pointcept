# ScanNetpp Benchmark constants
# Semantic classes, 100
CLASS_LABELS_PP = (
    "wall",
    "ceiling",
    "floor",
    "table",
    "door",
    "ceiling lamp",
    "cabinet",
    "blinds",
    "curtain",
    "chair",
    "storage cabinet",
    "office chair",
    "bookshelf",
    "whiteboard",
    "window",
    "box",
    "window frame",
    "monitor",
    "shelf",
    "doorframe",
    "pipe",
    "heater",
    "kitchen cabinet",
    "sofa",
    "windowsill",
    "bed",
    "shower wall",
    "trash can",
    "book",
    "plant",
    "blanket",
    "tv",
    "computer tower",
    "kitchen counter",
    "refrigerator",
    "jacket",
    "electrical duct",
    "sink",
    "bag",
    "picture",
    "pillow",
    "towel",
    "suitcase",
    "backpack",
    "crate",
    "keyboard",
    "rack",
    "toilet",
    "paper",
    "printer",
    "poster",
    "painting",
    "microwave",
    "board",
    "shoes",
    "socket",
    "bottle",
    "bucket",
    "cushion",
    "basket",
    "shoe rack",
    "telephone",
    "file folder",
    "cloth",
    "blind rail",
    "laptop",
    "plant pot",
    "exhaust fan",
    "cup",
    "coat hanger",
    "light switch",
    "speaker",
    "table lamp",
    "air vent",
    "clothes hanger",
    "kettle",
    "smoke detector",
    "container",
    "power strip",
    "slippers",
    "paper bag",
    "mouse",
    "cutting board",
    "toilet paper",
    "paper towel",
    "pot",
    "clock",
    "pan",
    "tap",
    "jar",
    "soap dispenser",
    "binder",
    "bowl",
    "tissue box",
    "whiteboard eraser",
    "toilet brush",
    "spray bottle",
    "headphones",
    "stapler",
    "marker",
)

# Instance classes, 84
INST_LABELS_PP = (
    "table",
    "door",
    "ceiling lamp",
    "cabinet",
    "blinds",
    "curtain",
    "chair",
    "storage cabinet",
    "office chair",
    "bookshelf",
    "whiteboard",
    "window",
    "box",
    "monitor",
    "shelf",
    "heater",
    "kitchen cabinet",
    "sofa",
    "bed",
    "trash can",
    "book",
    "plant",
    "blanket",
    "tv",
    "computer tower",
    "refrigerator",
    "jacket",
    "sink",
    "bag",
    "picture",
    "pillow",
    "towel",
    "suitcase",
    "backpack",
    "crate",
    "keyboard",
    "rack",
    "toilet",
    "printer",
    "poster",
    "painting",
    "microwave",
    "shoes",
    "socket",
    "bottle",
    "bucket",
    "cushion",
    "basket",
    "shoe rack",
    "telephone",
    "file folder",
    "laptop",
    "plant pot",
    "exhaust fan",
    "cup",
    "coat hanger",
    "light switch",
    "speaker",
    "table lamp",
    "kettle",
    "smoke detector",
    "container",
    "power strip",
    "slippers",
    "paper bag",
    "mouse",
    "cutting board",
    "toilet paper",
    "paper towel",
    "pot",
    "clock",
    "pan",
    "tap",
    "jar",
    "soap dispenser",
    "binder",
    "bowl",
    "tissue box",
    "whiteboard eraser",
    "toilet brush",
    "spray bottle",
    "headphones",
    "stapler",
    "marker",
)

_base_ = [
    "../_base_/default_runtime.py",
    "../_base_/dataset/scannetpp.py",
]

# misc custom setting
batch_size = 2  # bs: total bs in all gpus
num_worker = 24
mix_prob = 0
empty_cache = False
enable_amp = True
evaluate = True

wandb_project_name = "pointcept"
wandb_tags = ["SGIFormer"]
enable_wandb = True
use_step_logging = True
log_every = 500
save_freq = 5

class_names = INST_LABELS_PP
class_ids = [CLASS_LABELS_PP.index(c) for c in INST_LABELS_PP]
num_classes = len(class_names)

segment_ignore_index = (-1,)
semantic_num_classes = num_classes
num_channels = 32
weight = None  # Add the weights path here

model = dict(
    type="SGIFormer",
    backbone=dict(
        type="SpUNet-v2m1",
        in_channels=6,
        num_channels=num_channels,
        num_planes=[num_channels * (i + 1) for i in range(5)],
        return_blocks=True,
    ),
    decoder=dict(
        type="ScanNetPPSGIFormerDecoder",
        num_class=semantic_num_classes,
        in_channel=num_channels,
        dec_num_layer=3,
        num_sample_query=200,
        num_learn_query=200,
        d_model=256,
        nhead=8,
        hidden_dim=1024,
        dropout=0.0,
        activation_fn="gelu",
        attn_mask=True,
        use_score=False,
        alpha=0.4,
    ),
    criterion=dict(
        type="InstanceCriterion",
        matcher=dict(
            type="HungarianMatcher",
            costs=[
                dict(type="QueryClassificationCost", weight=0.5),
                dict(type="MaskBCECost", weight=1.0),
                dict(type="MaskDiceCost", weight=1.0),
            ],
        ),
        loss_weight=[0.8, 1.0, 1.0, 0.5, 0.4, 0.4],
        num_classes=semantic_num_classes,
        non_object_weight=0.1,
        fix_dice_loss_weight=False,
        iter_matcher=True,
        fix_mean_loss=True,
    ),
    fix_module=[],
    semantic_num_classes=semantic_num_classes,
    semantic_ignore_index=-1,
    segment_ignore_index=segment_ignore_index,
    instance_ignore_index=-1,
    topk_insts=300,
    score_thr=0.0,
    npoint_thr=100,
    nms=True,
)


epoch = 100
optimizer = dict(type="AdamW", lr=1e-8, weight_decay=0.05)
# scheduler = dict(type="PolyLR")
scheduler = dict(
    type="OneCycleLR",
    max_lr=[1e-8, 3e-8],
    pct_start=0.05,
    anneal_strategy="cos",
    div_factor=10.0,
    final_div_factor=1000.0,
)
param_dicts = [dict(keyword="head", lr=3e-8)]


# dataset settings
dataset_type = "ScanNetPPSpDataset"
data_root = "data/scannetpp"

data = dict(
    # for the data, we need to load all categories
    num_classes=num_classes,
    ignore_label=-1,
    ignore_index=-1,
    names=class_names,
    ids=class_ids,
    train=dict(
        type=dataset_type,
        split="train_grid1mm_chunk6x6_stride3x3",
        data_root=data_root,
        transform=[
            dict(type="ToTensor"),
            dict(type="InsClassMapT", ins_cls_ids=class_ids),
            dict(type="MeanShiftT"),
            dict(
                type="RandomDropoutT", dropout_ratio=0.2, dropout_application_ratio=0.5
            ),
            dict(type="RandomFlipT", p=0.5),
            dict(
                type="RandomRotateT", angle=[-1, 1], axis="z", center=[0, 0, 0], p=0.95
            ),
            dict(type="RandomRotateT", angle=[-1 / 64, 1 / 64], axis="x", p=0.5),
            dict(type="RandomRotateT", angle=[-1 / 64, 1 / 64], axis="y", p=0.5),
            dict(type="RandomScaleT", scale=[0.8, 1.2]),
            dict(type="RandomTranslationT", shift=[0.1, 0.1, 0.1]),
            dict(
                type="CustomElasticDistortionT",
                distortion_params=[[10, 60], [30, 180]],
                p=0.5,
            ),
            dict(type="ChromaticAutoContrastT", p=0.2, blend_factor=None),
            dict(type="ChromaticTranslationT", p=0.95, ratio=0.1),
            dict(type="ChromaticJitterT", p=0.95, std=0.05),
            dict(type="SphereCropT", sample_rate=0.8, mode="random"),
            dict(
                type="Copy",
                keys_dict={
                    "coord": "origin_coord",
                    "instance": "origin_instance",
                    "segment": "origin_segment",
                },
            ),
            dict(
                type="CustomGridSampleT",
                grid_size=0.02,
                hash_type="fnv",
                mode="train",
                return_grid_coord=True,
                return_inverse=True,
                keys=("coord", "color", "instance", "segment"),
            ),
            dict(type="NormalizeColorT"),
            dict(
                type="InstanceParserT",
                segment_ignore_index=segment_ignore_index,
                instance_ignore_index=-1,
            ),
            dict(
                type="Collect",
                keys=(
                    "coord",
                    "origin_coord",
                    "grid_coord",
                    "segment",
                    "origin_segment",
                    "instance",
                    "origin_instance",
                    "instance_centroid",
                    "superpoint",
                    "inverse",
                ),
                feat_keys=("color", "coord"),
                offset_keys_dict=dict(offset="coord", origin_offset="origin_coord"),
            ),
        ],
        test_mode=False,
    ),
    val=dict(
        type=dataset_type,
        split="val",
        data_root=data_root,
        transform=[
            dict(type="ToTensor"),
            dict(type="InsClassMapT", ins_cls_ids=class_ids),
            dict(type="MeanShiftT"),
            dict(type="CustomElasticDistortionT", p=0.0),
            dict(
                type="Copy",
                keys_dict={
                    "coord": "origin_coord",
                    "instance": "origin_instance",
                    "segment": "origin_segment",
                },
            ),
            dict(
                type="CustomGridSampleT",
                grid_size=0.02,
                hash_type="fnv",
                mode="train",
                return_grid_coord=True,
                return_inverse=True,
                keys=("coord", "color", "instance", "segment"),
            ),
            dict(type="NormalizeColorT"),
            dict(
                type="InstanceParserT",
                segment_ignore_index=segment_ignore_index,
                instance_ignore_index=-1,
            ),
            dict(
                type="Collect",
                keys=(
                    "coord",
                    "origin_coord",
                    "grid_coord",
                    "segment",
                    "origin_segment",
                    "instance",
                    "origin_instance",
                    "instance_centroid",
                    "superpoint",
                    "inverse",
                ),
                feat_keys=("color", "coord"),
                offset_keys_dict=dict(offset="coord", origin_offset="origin_coord"),
            ),
        ],
        test_mode=False,
    ),
    test=dict(
        type=dataset_type,
        split="val",
        data_root=data_root,
        transform=[
            dict(type="ToTensor"),
            dict(type="InsClassMapT", ins_cls_ids=class_ids),
            dict(type="MeanShiftT"),
            dict(type="CustomElasticDistortionT", p=0.0),
            dict(
                type="Copy",
                keys_dict={
                    "coord": "origin_coord",
                    "instance": "origin_instance",
                    "segment": "origin_segment",
                },
            ),
            dict(
                type="CustomGridSampleT",
                grid_size=0.02,
                hash_type="fnv",
                mode="train",
                return_grid_coord=True,
                return_inverse=True,
                keys=("coord", "color", "instance", "segment"),
            ),
            dict(type="NormalizeColorT"),
            dict(
                type="InstanceParserT",
                segment_ignore_index=segment_ignore_index,
                instance_ignore_index=-1,
            ),
            dict(
                type="Collect",
                keys=(
                    "coord",
                    "origin_coord",
                    "grid_coord",
                    "segment",
                    "origin_segment",
                    "instance",
                    "origin_instance",
                    "instance_centroid",
                    "superpoint",
                    "inverse",
                ),
                feat_keys=("color", "coord"),
                offset_keys_dict=dict(offset="coord", origin_offset="origin_coord"),
            ),
        ],
        test_mode=False,
    ),
)


hooks = [
    dict(type="CheckpointLoader", keywords="module.", replacement="module."),
    dict(type="IterationTimer", warmup_iter=2),
    dict(type="InformationWriter"),
    dict(
        type="SPInsEvaluator",
        segment_ignore_index=segment_ignore_index,
        semantic_ignore_index=(-1,),
        instance_ignore_index=-1,
    ),
    dict(type="CheckpointSaver", save_freq=save_freq),
]

# Tester
tester_evaluator = "SP"
test = dict(type="InstanceSegTest", verbose=True)
